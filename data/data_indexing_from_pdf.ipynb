{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Obtaining dependency information for PyPDF2 from https://files.pythonhosted.org/packages/8e/5e/c86a5643653825d3c913719e788e41386bee415c2b87b4f955432f2de6b2/pypdf2-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/232.6 kB ? eta -:--:--\n",
      "   ---------- ---------------------------- 61.4/232.6 kB 812.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 232.6/232.6 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#! pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1774,
     "status": "ok",
     "timestamp": 1749362976189,
     "user": {
      "displayName": "SeungMin Baek",
      "userId": "13244712800838483916"
     },
     "user_tz": -540
    },
    "id": "QR4Made_AH4J",
    "outputId": "525cd18b-2fbd-4918-e01c-c6bbaa79c823"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baek2\\AppData\\Local\\Temp\\ipykernel_41108\\804421021.py:3: DeprecationWarning: Importing from the 'elasticsearch.client' module is deprecated. Instead use 'elasticsearch' module for importing the client.\n",
      "  from elasticsearch.client import MlClient\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28325,
     "status": "ok",
     "timestamp": 1749363008474,
     "user": {
      "displayName": "SeungMin Baek",
      "userId": "13244712800838483916"
     },
     "user_tz": -540
    },
    "id": "nf8xUTwdAIqL",
    "outputId": "d82f0be4-2a59-4805-ae30-278c8a4317b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'instance-0000000000', 'cluster_name': 'b675458383584374af04fcee51788385', 'cluster_uuid': 'tEQ5uK6mSq6qmqujcMeoLg', 'version': {'number': '9.2.1', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '4ad0ef0e98a2e72fafbd79a19fa5cae2f026117d', 'build_date': '2025-11-06T22:07:39.673130621Z', 'build_snapshot': False, 'lucene_version': '10.3.1', 'minimum_wire_compatibility_version': '8.19.0', 'minimum_index_compatibility_version': '8.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "# ES 클라이언트 정의\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "url = os.getenv(\"ELASTIC_CLOUD_URL\")\n",
    "api_id = os.getenv(\"ELASTIC_API_ID\")\n",
    "api_key = os.getenv(\"ELASTIC_API_KEY\")\n",
    "es_model_id = os.getenv(\"ELASTIC_MODEL_ID\")\n",
    "\n",
    "\n",
    "client = Elasticsearch(\n",
    "    url,\n",
    "    api_key=(api_id, api_key)\n",
    ")\n",
    "\n",
    "print(client.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PDF > CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    단일 PDF 파일에서 모든 페이지 텍스트를 추출하는 함수.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    texts = []\n",
    "\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            texts.append(page_text)\n",
    "\n",
    "    return \"\\n\".join(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunk_text(\n",
    "    text: str,\n",
    "    max_chars: int = 1000,\n",
    "    overlap: int = 200\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    긴 텍스트를 max_chars 기준으로 잘라 chunk 리스트를 반환.\n",
    "    overlap만큼 앞 chunk와 겹치게 슬라이딩 윈도우 형태로 자름.\n",
    "    \"\"\"\n",
    "    text = \" \".join(text.split())\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "\n",
    "    while start < text_length:\n",
    "        end = start + max_chars\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        # 다음 chunk의 시작 인덱스 (overlap 적용)\n",
    "        start = end - overlap\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if start >= text_length:\n",
    "            break\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pdf_chunk_dataframe(\n",
    "    folder_path: str,\n",
    "    max_chars: int = 1000,\n",
    "    overlap: int = 200\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    주어진 폴더에서 모든 PDF를 읽고\n",
    "    파일별로 텍스트 추출 → chunking → DataFrame 생성.\n",
    "    컬럼: filename, chunk_seq, chunk_text\n",
    "    \"\"\"\n",
    "    pdf_files = glob.glob(os.path.join(folder_path, \"*.pdf\"))\n",
    "\n",
    "    records: List[Dict] = []\n",
    "\n",
    "    for pdf_path in pdf_files:\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        full_text = extract_text_from_pdf(pdf_path)\n",
    "        chunks = chunk_text(full_text, max_chars=max_chars, overlap=overlap)\n",
    "\n",
    "        for i, chunk in enumerate(chunks, start=1):\n",
    "            records.append(\n",
    "                {\n",
    "                    \"filename\": filename,\n",
    "                    \"chunk_seq\": i,\n",
    "                    \"chunk_text\": chunk,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(records, columns=[\"filename\", \"chunk_seq\", \"chunk_text\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf\n",
      "Processing: 4주차 ElasticSearch.pdf\n",
      "Processing: 5주차 LLM 이해와 PromptEngineering 9월 30일.pdf\n",
      "Processing: 7주차 생성형AI 검색 기초 - 벡터검색과 RAG_1014.pdf\n",
      "Processing: LangChain 기초_별첨.pdf\n",
      "Processing: 제10강 검색에이전트와 LangChain LangGraph.pdf\n",
      "Processing: 제11강 LangChain LangGraph를 이용한 AgenticRAG 개발.pdf\n",
      "Processing: 제12강 Multi-Hop .pdf\n",
      "                             filename  chunk_seq  \\\n",
      "0  3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          1   \n",
      "1  3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          2   \n",
      "2  3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          3   \n",
      "3  3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          4   \n",
      "4  3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          5   \n",
      "\n",
      "                                          chunk_text  \n",
      "0  빅데이터 정보검색 제3강정보검색 개요: 검색랭킹모델과평가 황영숙 (youngsook...  \n",
      "1  VectorSpaceModel ): 문서와 질의를 고차원 벡터로 표현하고 , 두 벡...  \n",
      "2   않음 •대다수 사용자는 불리언 질의를 작성하는 데 어려움을 느끼거나 , 작성하는 ...  \n",
      "3  ccard (A,B) = 0if A ∩ B = 0 •한계점 •단어 빈도(term f...  \n",
      "4  00 4 sunday 1,000 3 fly 10,000 2 under 100,000...  \n"
     ]
    }
   ],
   "source": [
    "folder_path = \"D:/workspace/대학원/25년도2학기/정보검색프로젝트/색인데이터\"\n",
    "\n",
    "max_chars = 1000\n",
    "overlap = 200\n",
    "\n",
    "df = build_pdf_chunk_dataframe(\n",
    "    folder_path=folder_path,\n",
    "    max_chars=max_chars,\n",
    "    overlap=overlap\n",
    "    )\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'빅데이터 정보검색 제3강정보검색 개요: 검색랭킹모델과평가 황영숙 (youngsook_hwang@korea.ac.kr) 정보검색개요 CollectionUser task Info need Query ResultsSearch engine Query refinement 정보 검색 개요 •정보 검색의 핵심 구성요소 •색인 (Indexing) : 수많은 문서를 효율적으로 검색할 수 있도록 구조화 하는 과정 •전처리 •토큰화 (Tokenization): 문서를 단어 단위로 쪼개는 과정 •불용어 제거(Stop Word Removal): ‘ 은’, ‘는‘ , ‘이‘, ‘가‘, ‘the’, ‘a’ 등 의미없는 단어 제거 •어간추출 (Stemming)/ 표제어 추출(Lemmatization): 단어의 원형 복원(예: runs →run, running→run, 먹었다→ 먹다) •키워드 역색인 (Inverted Index): 각 토큰이 어느 문서에서 출현했는지 기록하는 자료구조 •질의(Query): 사용자가 찾는 정보의 표현 •키워드 질의 •자연어 질의: ‘인공지능의 최신 연구동향에 대한 논문을 찾아줘 ‘와 같은 자연어 질문 •랭킹(Ranking): 문서와 질의간 유사도를 계산하여 질의와 관련된 문서를 중요도 순으로 나열하는 과정 •TF-IDF: 토큰 빈도(문서 내 특정 단어의 출현 빈도)와 역문서 빈도(전체 문서 중 특정 단어가 포함된 문서의 수)를 사 용하여 문서 내 용어의 중요도를 평가하는 가장 기본적인 방법 •BM25: TF -IDF를 개선한 확률적 모델로 , 많은 검색 엔진에서 기본 랭킹 알고리즘으로 사용 •벡터공간 모델(VectorSpaceModel ): 문서와 질의를 고차원 벡터로 표현하고 , 두 벡터 간의 코사인 유사도 (Cosine Similarity) 를 측정하여 랭킹. 최근 워드임베딩 , BERT 와 같은 딥러닝 기반의 언어 모델을 많이 사용 정보 검색 개요 •정보검색의 성능을 측정하는 주요 지표들 •정확성 (Relevance) : 검색된 문서가 사용자의 질의와 '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]['chunk_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VectorSpaceModel ): 문서와 질의를 고차원 벡터로 표현하고 , 두 벡터 간의 코사인 유사도 (Cosine Similarity) 를 측정하여 랭킹. 최근 워드임베딩 , BERT 와 같은 딥러닝 기반의 언어 모델을 많이 사용 정보 검색 개요 •정보검색의 성능을 측정하는 주요 지표들 •정확성 (Relevance) : 검색된 문서가 사용자의 질의와 얼마나 관련 있는지를 판단하는 주관적인 기준으로 전문가 그룹이 판단 •정밀도 (Precision): 검색된 문서 중 실제로 관련 있는 문서의 비율 •재현율 (Recall): 전체 관련 문서 중 실제로 검색된 문서의 비율 •F1-점수(F1-score): 정밀도와 재현율의 조화 평균 •그외 지표 •MAP(Mean Average Precision) : 질의에 대한 평균 정밀도를 여러 질의에 대해 평균낸 값 •nDCG (normalized Discounted Cumulative Gain) : 랭킹 순서를 고려하여 상위 랭크의 중요도를 높게 평가하는 지표 랭킹 •Ranked Retrieval •Scoring Documents •Tf-Idfweighting •Vector Space Model •BM25, BM25F 랭킹 기반 검색(Ranked Retrieval) •Boolean Query 의 장점과 한계 •블리언 질의: 문서가 질의와 일치하거나 , 그렇지 않거나 둘 중 하나 •장점 •자신의 요구사항과 문서 집합을 정확하게 이해하는 전문가 에게 유용 •애플리케이션이 수천 개의 결과를 쉽게 처리할 수 있어 응용 프로그램 에 적합 •한계 •대부분의 일반 사용자에게는 적합하지 않음 •대다수 사용자는 불리언 질의를 작성하는 데 어려움을 느끼거나 , 작성하는 것을 번거로워함 •대부분의 사용자는 수천 개의 결과 목록을 일일이 확인하는 것을 원하지 않음 •결과 수의 불균형 : 종종 결과의 수가 너무 적거나 (0개) 혹은 너무 많은(수천 개) 극단적 상황 초래 →적절한 수의 결과를 얻기 위해서는 상당한 수준의 질의 작성 기술이 필요 ('"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['chunk_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"pdf_chunks.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "executionInfo": {
     "elapsed": 2942,
     "status": "ok",
     "timestamp": 1749363049035,
     "user": {
      "displayName": "SeungMin Baek",
      "userId": "13244712800838483916"
     },
     "user_tz": -540
    },
    "id": "PNJq0TO_AgQR",
    "outputId": "68dccc06-0f0c-4547-c21a-26c550f2d34b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chunk_seq</th>\n",
       "      <th>chunk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>빅데이터 정보검색 제3강정보검색 개요: 검색랭킹모델과평가 황영숙 (youngsook...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>VectorSpaceModel ): 문서와 질의를 고차원 벡터로 표현하고 , 두 벡...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename  chunk_seq  \\\n",
       "0  3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          1   \n",
       "1  3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          2   \n",
       "\n",
       "                                          chunk_text  \n",
       "0  빅데이터 정보검색 제3강정보검색 개요: 검색랭킹모델과평가 황영숙 (youngsook...  \n",
       "1  VectorSpaceModel ): 문서와 질의를 고차원 벡터로 표현하고 , 두 벡...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class_info = pd.read_csv('./pdf_chunks.csv', encoding='utf-8-sig')\n",
    "class_info.loc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chunk_seq</th>\n",
       "      <th>chunk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>빅데이터 정보검색 제3강정보검색 개요: 검색랭킹모델과평가 황영숙 (youngsook...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>VectorSpaceModel ): 문서와 질의를 고차원 벡터로 표현하고 , 두 벡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>않음 •대다수 사용자는 불리언 질의를 작성하는 데 어려움을 느끼거나 , 작성하는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>ccard (A,B) = 0if A ∩ B = 0 •한계점 •단어 빈도(term f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>00 4 sunday 1,000 3 fly 10,000 2 under 100,000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>제12강 Multi-Hop .pdf</td>\n",
       "      <td>16</td>\n",
       "      <td>(Decomposed Retrieval ) •Self-Correction: 검색된 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>제12강 Multi-Hop .pdf</td>\n",
       "      <td>17</td>\n",
       "      <td>파악하고 , 이를 포함하는 다음 검색 쿼리를 생성해야 함(예: \"찰스 디킨스의 대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>제12강 Multi-Hop .pdf</td>\n",
       "      <td>18</td>\n",
       "      <td>ation) 단계의 주요 이슈 •복잡한 논리적 통합 (Complex Logical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>제12강 Multi-Hop .pdf</td>\n",
       "      <td>19</td>\n",
       "      <td>-to-Most Prompting •Denny Zhou, et al ., “Leas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>제12강 Multi-Hop .pdf</td>\n",
       "      <td>20</td>\n",
       "      <td>in Large Language Models”, 2023 •CoVe는 LLM이 생성...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filename  chunk_seq  \\\n",
       "0    3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          1   \n",
       "1    3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          2   \n",
       "2    3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          3   \n",
       "3    3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          4   \n",
       "4    3주차 검색개요 - 색인과 검색랭킹과 평가(part2).pdf          5   \n",
       "..                                  ...        ...   \n",
       "219                 제12강 Multi-Hop .pdf         16   \n",
       "220                 제12강 Multi-Hop .pdf         17   \n",
       "221                 제12강 Multi-Hop .pdf         18   \n",
       "222                 제12강 Multi-Hop .pdf         19   \n",
       "223                 제12강 Multi-Hop .pdf         20   \n",
       "\n",
       "                                            chunk_text  \n",
       "0    빅데이터 정보검색 제3강정보검색 개요: 검색랭킹모델과평가 황영숙 (youngsook...  \n",
       "1    VectorSpaceModel ): 문서와 질의를 고차원 벡터로 표현하고 , 두 벡...  \n",
       "2     않음 •대다수 사용자는 불리언 질의를 작성하는 데 어려움을 느끼거나 , 작성하는 ...  \n",
       "3    ccard (A,B) = 0if A ∩ B = 0 •한계점 •단어 빈도(term f...  \n",
       "4    00 4 sunday 1,000 3 fly 10,000 2 under 100,000...  \n",
       "..                                                 ...  \n",
       "219  (Decomposed Retrieval ) •Self-Correction: 검색된 ...  \n",
       "220   파악하고 , 이를 포함하는 다음 검색 쿼리를 생성해야 함(예: \"찰스 디킨스의 대...  \n",
       "221  ation) 단계의 주요 이슈 •복잡한 논리적 통합 (Complex Logical ...  \n",
       "222  -to-Most Prompting •Denny Zhou, et al ., “Leas...  \n",
       "223  in Large Language Models”, 2023 •CoVe는 LLM이 생성...  \n",
       "\n",
       "[224 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ES 색인 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"class-info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 임베딩을 위한 ingest pipeline 추가 \n",
    "\n",
    "client.ingest.put_pipeline(\n",
    "    id=\"pipeline\",\n",
    "    processors=[\n",
    "        {\n",
    "            \"inference\": {\n",
    "                \"model_id\": es_model_id,\n",
    "                \"field_map\": {\"chunk_text\": \"text_field\"},  # field to embed: information\n",
    "                \"target_field\": \"chunk_embedding\",  # embedded field: information_embedding\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 색인을 위한 analyzer, mapping 구성, pipeline 연결 \n",
    "\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index.mapping.exclude_source_vectors\": False, \n",
    "        \"analysis\": {\n",
    "            \"tokenizer\": {\n",
    "                \"nori_tokenizer_custom\": {\n",
    "                    \"type\": \"nori_tokenizer\",\n",
    "                    \"decompound_mode\": \"mixed\"\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"korean_nori\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"nori_tokenizer_custom\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"index\": {\n",
    "        \"number_of_replicas\": \"1\",\n",
    "        \"number_of_shards\": \"1\",\n",
    "        \"default_pipeline\": \"pipeline\",\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"filename\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"chunk_seq\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"chunk_text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"korean_nori\"\n",
    "            },\n",
    "            \"chunk_embedding.predicted_value\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing index: class-info\n"
     ]
    }
   ],
   "source": [
    "# if client.indices.exists(index=index_name):\n",
    "#     client.indices.delete(index=index_name)\n",
    "#     print(f\"Deleted existing index: {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 인덱스 생성\n",
    "response = client.indices.create(\n",
    "    index=index_name,\n",
    "    body=index_body\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246590,
     "status": "ok",
     "timestamp": 1749366388134,
     "user": {
      "displayName": "SeungMin Baek",
      "userId": "13244712800838483916"
     },
     "user_tz": -540
    },
    "id": "e3956274",
    "outputId": "0b39858e-41a4-456b-bb08-edad56960626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed document with index 0\n",
      "Successfully indexed document with index 30\n",
      "Successfully indexed document with index 60\n",
      "Successfully indexed document with index 90\n",
      "Successfully indexed document with index 120\n",
      "Successfully indexed document with index 150\n",
      "Successfully indexed document with index 180\n",
      "Successfully indexed document with index 210\n"
     ]
    }
   ],
   "source": [
    "# 2.4 데이터 색인\n",
    "\n",
    "indexed_results = []\n",
    "\n",
    "for index, row in class_info.iterrows():\n",
    "    doc_source = {\n",
    "        \"filename\": row['filename'] if pd.notna(row['filename']) else None,\n",
    "        \"chunk_seq\": row['chunk_seq'] if pd.notna(row['chunk_seq']) else None,\n",
    "        \"chunk_text\": row['chunk_text'] if pd.notna(row['chunk_text']) else None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = client.index(index=\"class-info\", document=doc_source, id=str(index))\n",
    "        indexed_results.append({'index': index, 'status': 'success', 'response': response})\n",
    "        if index % 30 == 0:\n",
    "            print(f\"Successfully indexed document with index {index}\")\n",
    "    except Exception as e:\n",
    "        indexed_results.append({'index': index, 'status': 'failed', 'error': str(e)})\n",
    "        print(f\"Failed to index document with index {index}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLx80HdkXq_r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMS+C+jMgnvvqKumRbPkRn+",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
