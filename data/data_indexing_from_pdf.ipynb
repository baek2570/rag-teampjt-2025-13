{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1774,
     "status": "ok",
     "timestamp": 1749362976189,
     "user": {
      "displayName": "SeungMin Baek",
      "userId": "13244712800838483916"
     },
     "user_tz": -540
    },
    "id": "QR4Made_AH4J",
    "outputId": "525cd18b-2fbd-4918-e01c-c6bbaa79c823"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28325,
     "status": "ok",
     "timestamp": 1749363008474,
     "user": {
      "displayName": "SeungMin Baek",
      "userId": "13244712800838483916"
     },
     "user_tz": -540
    },
    "id": "nf8xUTwdAIqL",
    "outputId": "d82f0be4-2a59-4805-ae30-278c8a4317b9"
   },
   "outputs": [],
   "source": [
    "# ES 클라이언트 정의\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "url = os.getenv(\"ELASTIC_CLOUD_URL\")\n",
    "api_id = os.getenv(\"ELASTIC_API_ID\")\n",
    "api_key = os.getenv(\"ELASTIC_API_KEY\")\n",
    "es_model_id = os.getenv(\"ELASTIC_MODEL_ID\")\n",
    "\n",
    "\n",
    "client = Elasticsearch(\n",
    "    url,\n",
    "    api_key=(api_id, api_key)\n",
    ")\n",
    "\n",
    "print(client.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PDF > CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    단일 PDF 파일에서 모든 페이지 텍스트를 추출하는 함수.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    texts = []\n",
    "\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            texts.append(page_text)\n",
    "\n",
    "    return \"\\n\".join(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunk_text(\n",
    "    text: str,\n",
    "    max_chars: int = 1000,\n",
    "    overlap: int = 200\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    긴 텍스트를 max_chars 기준으로 잘라 chunk 리스트를 반환.\n",
    "    overlap만큼 앞 chunk와 겹치게 슬라이딩 윈도우 형태로 자름.\n",
    "    \"\"\"\n",
    "    text = \" \".join(text.split())\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "\n",
    "    while start < text_length:\n",
    "        end = start + max_chars\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        # 다음 chunk의 시작 인덱스 (overlap 적용)\n",
    "        start = end - overlap\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if start >= text_length:\n",
    "            break\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pdf_chunk_dataframe(\n",
    "    folder_path: str,\n",
    "    max_chars: int = 1000,\n",
    "    overlap: int = 200\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    주어진 폴더에서 모든 PDF를 읽고\n",
    "    파일별로 텍스트 추출 → chunking → DataFrame 생성.\n",
    "    컬럼: filename, chunk_seq, chunk_text\n",
    "    \"\"\"\n",
    "    pdf_files = glob.glob(os.path.join(folder_path, \"*.pdf\"))\n",
    "\n",
    "    records: List[Dict] = []\n",
    "\n",
    "    for pdf_path in pdf_files:\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        full_text = extract_text_from_pdf(pdf_path)\n",
    "        chunks = chunk_text(full_text, max_chars=max_chars, overlap=overlap)\n",
    "\n",
    "        for i, chunk in enumerate(chunks, start=1):\n",
    "            records.append(\n",
    "                {\n",
    "                    \"filename\": filename,\n",
    "                    \"chunk_seq\": i,\n",
    "                    \"chunk_text\": chunk,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(records, columns=[\"filename\", \"chunk_seq\", \"chunk_text\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 폴더 내 PDF파일을 읽어서 데이터 프레임으로 저장\n",
    "\n",
    "folder_path = \"D:/workspace/대학원/25년도2학기/정보검색프로젝트/색인데이터\"\n",
    "\n",
    "max_chars = 1000\n",
    "overlap = 200\n",
    "\n",
    "df = build_pdf_chunk_dataframe(\n",
    "    folder_path=folder_path,\n",
    "    max_chars=max_chars,\n",
    "    overlap=overlap\n",
    "    )\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 데이터 프레임을 CSV로 저장\n",
    "\n",
    "df.to_csv(\"pdf_chunks.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "executionInfo": {
     "elapsed": 2942,
     "status": "ok",
     "timestamp": 1749363049035,
     "user": {
      "displayName": "SeungMin Baek",
      "userId": "13244712800838483916"
     },
     "user_tz": -540
    },
    "id": "PNJq0TO_AgQR",
    "outputId": "68dccc06-0f0c-4547-c21a-26c550f2d34b"
   },
   "outputs": [],
   "source": [
    "\n",
    "class_info = pd.read_csv('./pdf_chunks.csv', encoding='utf-8-sig')\n",
    "class_info.loc[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ES 색인 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"class-info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 임베딩을 위한 ingest pipeline 추가 \n",
    "\n",
    "client.ingest.put_pipeline(\n",
    "    id=\"pipeline\",\n",
    "    processors=[\n",
    "        {\n",
    "            \"inference\": {\n",
    "                \"model_id\": es_model_id,  # embedding에 활용할 model_id 지정\n",
    "                \"field_map\": {\"chunk_text\": \"text_field\"},  # embedding 대상 text를 chunk_text 필드로 지정\n",
    "                \"target_field\": \"chunk_embedding\", # embedding 결과를 chunk_embedding 필드에 저장\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 색인을 위한 analyzer, mapping 구성, pipeline 연결 \n",
    "\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index.mapping.exclude_source_vectors\": False, \n",
    "        \"analysis\": {\n",
    "            \"tokenizer\": {\n",
    "                \"nori_tokenizer_custom\": {\n",
    "                    \"type\": \"nori_tokenizer\",\n",
    "                    \"decompound_mode\": \"mixed\"\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"korean_nori\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"nori_tokenizer_custom\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"index\": {\n",
    "        \"number_of_replicas\": \"1\",\n",
    "        \"number_of_shards\": \"1\",\n",
    "        \"default_pipeline\": \"pipeline\",\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"filename\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"chunk_seq\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"chunk_text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"korean_nori\"\n",
    "            },\n",
    "            \"chunk_embedding.predicted_value\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if client.indices.exists(index=index_name):\n",
    "#     client.indices.delete(index=index_name)\n",
    "#     print(f\"Deleted existing index: {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 인덱스 생성\n",
    "response = client.indices.create(\n",
    "    index=index_name,\n",
    "    body=index_body\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246590,
     "status": "ok",
     "timestamp": 1749366388134,
     "user": {
      "displayName": "SeungMin Baek",
      "userId": "13244712800838483916"
     },
     "user_tz": -540
    },
    "id": "e3956274",
    "outputId": "0b39858e-41a4-456b-bb08-edad56960626"
   },
   "outputs": [],
   "source": [
    "# 2.4 데이터 색인\n",
    "\n",
    "indexed_results = []\n",
    "\n",
    "for index, row in class_info.iterrows():\n",
    "    doc_source = {\n",
    "        \"filename\": row['filename'] if pd.notna(row['filename']) else None,\n",
    "        \"chunk_seq\": row['chunk_seq'] if pd.notna(row['chunk_seq']) else None,\n",
    "        \"chunk_text\": row['chunk_text'] if pd.notna(row['chunk_text']) else None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = client.index(index=\"class-info\", document=doc_source, id=str(index))\n",
    "        indexed_results.append({'index': index, 'status': 'success', 'response': response})\n",
    "        if index % 30 == 0:\n",
    "            print(f\"Successfully indexed document with index {index}\")\n",
    "    except Exception as e:\n",
    "        indexed_results.append({'index': index, 'status': 'failed', 'error': str(e)})\n",
    "        print(f\"Failed to index document with index {index}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMS+C+jMgnvvqKumRbPkRn+",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
